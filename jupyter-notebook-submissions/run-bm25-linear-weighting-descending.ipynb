{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTerrier Notebook for Full-Rank Submissions\n",
    "\n",
    "This notebook serves as a baseline full-rank submission for [TIRA](https://tira.io)/[TIREx](https://tira.io/tirex) that builds a PyTerrier index and subsequently creates a run with BM25."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Ensure Libraries are Imported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "\n",
    "# Detect if we are in the TIRA sandbox\n",
    "# Install the required dependencies if we are not in the sandbox.\n",
    "if 'TIRA_DATASET_ID' not in os.environ:\n",
    "    !pip3 install python-terrier tira==0.0.88 ir_datasets\n",
    "else:\n",
    "    print('We are in the TIRA sandbox.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tira.third_party_integrations import ensure_pyterrier_is_loaded, persist_and_normalize_run\n",
    "\n",
    "# this loads and starts pyterrier so that it also works in the TIRA\n",
    "ensure_pyterrier_is_loaded()\n",
    "\n",
    "# PyTerrier must be imported after the call to ensure_pyterrier_is_loaded in TIRA.\n",
    "import pyterrier as pt\n",
    "from pyterrier.measures import *\n",
    "\n",
    "if not pt.started():\n",
    "    pt.init(boot_packages=['mam10eks:custom-terrier-token-processing:0.0.1', 'com.github.terrierteam:terrier-prf:-SNAPSHOT'])\n",
    "    from jnius import autoclass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pt.get_dataset('irds:ir-lab-jena-leipzig-wise-2023/validation-20231104-training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_linear_weight_function(value, max_length):\n",
    "    \"\"\"Inverse linear weight function, which applies linearly increasing weights.\"\"\"\n",
    "    if max_length == 0:\n",
    "        return 1.0\n",
    "    return value / max_length\n",
    "\n",
    "def english_tokenizer(string):\n",
    "    \"\"\"Tokenizes the input string according to the english terrier tokenizer and generates a list of tokens.\"\"\"\n",
    "    english_tokeniser = pt.TerrierTokeniser.english\n",
    "    english_tokeniser = pt.TerrierTokeniser._to_obj(english_tokeniser)\n",
    "    english_tokeniser = pt.TerrierTokeniser._to_class(english_tokeniser)\n",
    "\n",
    "    tokeniser = \"org.terrier.indexing.tokenisation.\" + english_tokeniser\n",
    "    tokenobj = pt.autoclass(tokeniser)()\n",
    "    _query_fn = tokenobj.getTokens\n",
    "    return _query_fn(string)\n",
    "\n",
    "\n",
    "def apply_query_term_weighing(query, weight_function):\n",
    "    query_parts = english_tokenizer(query)\n",
    "    query_length = len(query_parts)\n",
    "    weights = [weight_function(x, query_length - 1) for x in range(query_length)]\n",
    "\n",
    "    return \" \".join(\n",
    "        [f\"{query_part}^{weight}\" for query_part, weight in zip(query_parts, weights)]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = data.get_topics(\"title\")\n",
    "for idx, entry in topics.iterrows():\n",
    "    query = entry[\"query\"]\n",
    "    query = apply_query_term_weighing(query, inverse_linear_weight_function)\n",
    "    topics.at[idx, \"query\"] = query\n",
    "topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Build the Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Build index:')\n",
    "# Both the indexer and batch retrieve use terriers default porter stemmer and a default stopword list (englisch)\n",
    "iter_indexer = pt.IterDictIndexer(\"/tmp/index\", overwrite = True, blocks = True,meta = {'docno':100, 'text': 20480}, stemmer = 'PorterStemmer')\n",
    "!rm -Rf /tmp/index\n",
    "index_ref = iter_indexer.index(data.get_corpus_iter())\n",
    "\n",
    "print('Done. Index is created')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Create the Retrieval Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pt.IndexFactory.of(index_ref)\n",
    "\n",
    "bm25 = pt.BatchRetrieve(index, wmodel=\"BM25\", verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4.1: Add Query Expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pipeline\n",
    "pipe = bm25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Create the Run and Persist the Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Create run')\n",
    "run = pipe.transform(topics).fillna(0)\n",
    "print('Done, run was created')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Run Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_and_normalize_run(run, 'bm25-linear-weighing-descending')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
