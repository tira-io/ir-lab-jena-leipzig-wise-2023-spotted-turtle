{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTerrier Notebook for Full-Rank Submissions\n",
    "\n",
    "This notebook serves as a baseline full-rank submission for [TIRA](https://tira.io)/[TIREx](https://tira.io/tirex) that builds a PyTerrier index and subsequently creates a run with BM25."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Ensure Libraries are Imported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31merror\u001b[0m: \u001b[1mexternally-managed-environment\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m This environment is externally managed\n",
      "\u001b[31m╰─>\u001b[0m To install Python packages system-wide, try apt install\n",
      "\u001b[31m   \u001b[0m python3-xyz, where xyz is the package you are trying to\n",
      "\u001b[31m   \u001b[0m install.\n",
      "\u001b[31m   \u001b[0m \n",
      "\u001b[31m   \u001b[0m If you wish to install a non-Debian-packaged Python package,\n",
      "\u001b[31m   \u001b[0m create a virtual environment using python3 -m venv path/to/venv.\n",
      "\u001b[31m   \u001b[0m Then use path/to/venv/bin/python and path/to/venv/bin/pip. Make\n",
      "\u001b[31m   \u001b[0m sure you have python3-full installed.\n",
      "\u001b[31m   \u001b[0m \n",
      "\u001b[31m   \u001b[0m If you wish to install a non-Debian packaged Python application,\n",
      "\u001b[31m   \u001b[0m it may be easiest to use pipx install xyz, which will manage a\n",
      "\u001b[31m   \u001b[0m virtual environment for you. Make sure you have pipx installed.\n",
      "\u001b[31m   \u001b[0m \n",
      "\u001b[31m   \u001b[0m See /usr/share/doc/python3.11/README.venv for more information.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: If you believe this is a mistake, please contact your Python installation or OS distribution provider. You can override this, at the risk of breaking your Python installation or OS, by passing --break-system-packages.\n",
      "\u001b[1;36mhint\u001b[0m: See PEP 668 for the detailed specification.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import math\n",
    "import re\n",
    "\n",
    "# Detect if we are in the TIRA sandbox\n",
    "# Install the required dependencies if we are not in the sandbox.\n",
    "if 'TIRA_DATASET_ID' not in os.environ:\n",
    "    !pip3 install python-terrier tira==0.0.88 ir_datasets\n",
    "else:\n",
    "    print('We are in the TIRA sandbox.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tira.third_party_integrations import ensure_pyterrier_is_loaded, persist_and_normalize_run\n",
    "\n",
    "# this loads and starts pyterrier so that it also works in the TIRA\n",
    "ensure_pyterrier_is_loaded()\n",
    "\n",
    "# PyTerrier must be imported after the call to ensure_pyterrier_is_loaded in TIRA.\n",
    "import pyterrier as pt\n",
    "\n",
    "if not pt.started():\n",
    "    pt.init(boot_packages=['mam10eks:custom-terrier-token-processing:0.0.1', 'com.github.terrierteam:terrier-prf:-SNAPSHOT'])\n",
    "    from jnius import autoclass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pt.get_dataset('irds:ir-lab-jena-leipzig-wise-2023/validation-20231104-training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_weight_function(value, max_length):\n",
    "    \"\"\"Linear weight function, which applies linearly decreasing weights, such taht the last term has weight 1.\"\"\"\n",
    "    return (-value+max_length)/max_length\n",
    "\n",
    "def linear_inverse_weight_function(value, max_length):\n",
    "    \"\"\"Linear weight function, which applies linearly decreasing weights, such taht the last term has weight 1.\"\"\"\n",
    "    return value/max_length\n",
    "\n",
    "def centered_parabola_weight_function(value, max_length):\n",
    "    \"\"\"Centered parabola weight function, which applies decreasing and increasing weights, such taht the middle term has weight 1.\"\"\"\n",
    "    multiplier = 0.5\n",
    "    return (value*multiplier - (max_length-1)*multiplier*0.5)**2 + 1\n",
    "\n",
    "def log_weight_function(value, max_length):\n",
    "    \"\"\"Logarithmic weight function, which applies decreasing weights, such taht the last term has weight 1.\"\"\"\n",
    "    return - math.log2((value+0.1)/(value+(max_length-0.9)+0.1))\n",
    "\n",
    "def apply_query_term_weighing(query, weight_function):\n",
    "    query_parts = query.split() # TODO: PyTerrier Split\n",
    "    query_length = len(query_parts)\n",
    "    weights = [weight_function(x, query_length) for x in range(query_length)]\n",
    "\n",
    "    return \" \".join([f\"{query_part}^{weight}\" for query_part, weight in zip(query_parts,weights)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_corpus(data):\n",
    "    processed_corpus = []\n",
    "    for element in data.get_corpus_iter():\n",
    "        element['text'] = apply_query_term_weighing(element['text'], log_weight_function)\n",
    "        processed_corpus.append(element)\n",
    "\n",
    "    return processed_corpus\n",
    "\n",
    "processed_corpus = preprocess_corpus(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weightedTopics = data.get_topics('title')\n",
    "for entry in weightedTopics.iterrows():\n",
    "    query = entry[1][\"query\"]\n",
    "    query = apply_query_term_weighing(query, linear_weight_function)\n",
    "    entry[1][\"query\"] = query\n",
    "\n",
    "inverseWeightedTopics = data.get_topics('title')\n",
    "for entry in inverseWeightedTopics.iterrows():\n",
    "    query = entry[1][\"query\"]\n",
    "    query = apply_query_term_weighing(query, linear_inverse_weight_function)\n",
    "    entry[1][\"query\"] = query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Build the Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Build index:')\n",
    "# Both the indexer and batch retrieve use terriers default porter stemmer and a default stopword list (englisch)\n",
    "# TODO: consider adding french stopwords\n",
    "iter_indexer = pt.IterDictIndexer(\"/tmp/index\", overwrite = True, blocks = True,meta = {'docno':100, 'text': 20480}, stemmer = 'PorterStemmer')\n",
    "!rm -Rf /tmp/index\n",
    "index_ref = iter_indexer.index(processed_corpus)\n",
    "\n",
    "print('Done. Index is created')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Create the Retrieval Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pt.IndexFactory.of(index_ref)\n",
    "\n",
    "bm25 = pt.BatchRetrieve(index, wmodel=\"BM25\", verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4.1: Add Query Expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pipeline\n",
    "pipe = bm25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Create the Run and Persist the Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Create run')\n",
    "\n",
    "run = pipe(weightedTopics)\n",
    "run2 = pipe(inverseWeightedTopics)\n",
    "\n",
    "print('Done, run was created')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Run Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doesn't work in TIRA, only for local testing\n",
    "pt.Experiment(\n",
    "   [run, run2],\n",
    "   data.get_topics()[:50],\n",
    "   data.get_qrels(),\n",
    "   eval_metrics=[\"ndcg_5\"],\n",
    "   names=[\"BM25\", \"Spotted Turtle\"],\n",
    "   baseline=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_and_normalize_run(run, 'bm25-custom-stopwords')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
